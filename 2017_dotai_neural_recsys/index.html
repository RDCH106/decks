<!DOCTYPE html>
<html>
  <head>
    <title>Neural Recommender Systems</title>
    <meta charset="utf-8">
    <link rel="stylesheet" type="text/css" href="slides.css">
  </head>
  <body>
    <textarea id="source">
class: center, middle

# Neural Networks for Recommender Systems


<img width="200px" src="images/logo-dotai.png"/>

### Paris &nbsp; 2017

Olivier Grisel

.affiliations[
  ![Inria](images/inria-logo.png)
]

---
# Outline

### Recommender Systems

--

### Embeddings

--

### Architectures for Neural RecSys

---
class: middle, center

# Recommender Systems


---
class: middle, center, singleimg

![Amazon books](images/amazon_book_recos.png)


???

Product reco and Recommendations

Goal: Direction maximize sales / upsales


---
class: middle, center, singleimg

![Spotify](images/spotify_related_artists_recos.png)


---
class: middle, center, singleimg

![Spotify](images/spotify_weekly_recos.png)


???

- reduce UI friction / simplify navigation
- hide holes in a catalog
- maximize user satisfaction and improve user retention

---
class: middle, center, singleimg

![Twitter Who To Follow](images/twitter_recos.png)

???
Recommend people instead of products

Goals:

- Improve user onboarding / retention / engagement
- Indirectly: mindshare for ads and therefore

---
class: middle, center, singleimg

![Google](images/google_python_recos.png)

???

Search engines are now recommender systems

---
class: middle, center, singleimg

![Google](images/google_python_recos_inputs.png)

???

The query is now contextualized with the user history.

---
class: middle, center, singleimg

![Google](images/google_python_recos_webpages.png)

???

A google search is actually the results of 2 queries in 2 recsys:

- first the traditional web pages

---
class: middle, center, singleimg

![Google](images/google_python_recos_full.png)


???

The second recsys is the query for the best personnalized ad.

Personnalized ads are the business model of 2 of the 10 largest global
companies by market cap.

Other types of recos:

- apps on app stores

- status messages on social medias

...

---
class: middle, center

# RecSys 101

---

# Content-based

Inputs: user and item metadata

User gender, item publication date, director, actors...

--

# Collaborative Filtering

Inputs: user/item interactions

Stars, plays, likes, clicks

--

# Hybrid systems

???

Content-based: good for new users or new items

CF better for popular items and very active users

Hybrid: CF + metadata to mitigate the cold-start problem

---
# Explicit vs Implicit Feedback

**Explicit**

- Examples: review stars and votes

- Regression or ranking metrics

--

**Implicit**

- Examples: page views, plays, comments...

- Ranking metrics

???

Explicit: positive and negative feedback

Implicit: positive feedback only


Implicit feedback much more **abundant** than explicit feedback

Explicit feedback does not always reflect **actual user behaviors**

- Self-declared independent movie enthusiast but watch a majority of blockblusters

Implicit feedback can be **negative**

- Page view with very short dwell time
- Click on "next" button

Implicit (and Explicit) feedback distribution **impacted by UI/UX changes**
and the **RecSys deployment** itself.

---
# Matrix Factorization for CF

.center[
<img src="images/cf-mf.svg" width="600px" />
]

$$
L(U, V) = \sum\_{(i, j) \in D} || r\_{i,j} - \mathbf{u}\_i^T \cdot \mathbf{v}\_j ||_2^2 + \lambda (||U||\_2^2 + ||V||\_2^2) 
$$

???

R is observed feedback: ratings

Each row of R is represent the history of a user

Many missing entry: each user has seen less than 1% of the catalog

Model R by matrix multiplication of U by V with d dimensions

- Train $U$ and $V$ on observed ratings data $r\_{i, j}$
- Use $U^T V$ to find missing entries in sparse rating data matrix $R$

---
class: middle, center

# Embeddings

---
class: center, middle

| User  | Item  |
|-------|-------|
| 19483 | 45243 |
| 95727 | 39572 |
| 76244 | 83773 |
| 02584 | 94723 |
| 02584 | 45243 |
| 49138 | 20481 |
| 03957 | 25892 |
| 19483 | 25892 |
| ...   | ...   |

---
# Symbolic variables

### Recommender Systems

Item ids, user ids 

--

### Text tokens

Characters, words, bigrams..

--

### Categorical descriptors

Tags, movie genres, director name, visited URLs,
skills on a resume, product categories...

---

.center[
### Symbol $s$ in vocabulary $V$
]

---
# One-hot representation

$$onehot(\text{'salad'}) = [0, 0, 1, ..., 0] \in \\{0, 1\\}^{|V|}$$
<br/><br/>
.center[
<img src="images/word_onehot.svg" style="width: 400px;" />
]

<br/>

--

- Sparse, discrete, large dimension $|V|$
- Each axis has a meaning
- Symbols are equidistant from each other

.center[euclidean distance = $\sqrt{2}$]

---
# Embedding

$$embedding(\text{'salad'}) = [3.28, -0.45, ... 7.11] \in \mathbb{R}^d$$
<br/>
--

- Continuous and dense
- Can represent a huge vocabulary in low dimension, typically: $d \in \\{16, 32, ..., 4096\\}$
- Axis have no meaning _a priori_
- Embedding metric can capture semantic distance

--
<br/><br/>

### Neural Networks compute transformations on continuous vectors

---
# Implementation with Keras

Size of vocabulary $n = |V|$, size of embedding $d$

```py
# input: batch of integers
Embedding(output_dim=d, input_dim=n, input_length=1)
# output: batch of float vectors
```

--

- Equivalent to one-hot encoding multiplied by a weight matrix $\mathbf{W} \in \mathbb{R}^{n \times d}$:

$$embedding(s) = onehot(s) . \mathbf{W} = \mathbf{W}_s $$

---
# Distance and similarity in Embedding space

.left-column[
### Euclidean distance

$d(x,y) = || x - y ||_2$

]

--

.right-column[
### Cosine similarity

$cosine(x,y) = \frac{x \cdot y}{||x|| \cdot ||y||}$



]

???

Distance
- Simple with good properties
- Dependent on norm (embeddings usually unconstrained)

Cosine:
- Angle between points, regardless of norm
- $cosine(x,y) \in (-1,1)$
- Expected cosine similarity of random pairs of vectors is $0$

Alternatively: just the dot product

---
class: center, middle

# Architectures

---
# RecSys with Explicit Feedback

.center[
<img src="images/rec_archi_1.svg" style="width: 680px;" />
]

---
# Deep RecSys Architecture

.center[
<img src="images/rec_archi_2.svg" style="width: 680px;" />
]

---
# Deep RecSys with metadata

.center[
<img src="images/rec_archi_3.svg" style="width: 680px;" />
]

---
# Implicit Feedback: Triplet loss

.center[
<img src="images/rec_archi_implicit_2.svg" style="width: 580px;" />
]

---
# Deep Triplet Networks
.center[
<img src="images/rec_archi_implicit_1.svg" style="width: 580px;" />
]

---
# Training a Triplet Model

- Gather a set of positive pairs user $i$ and item $j$

- While model has not converged:

--
    - Shuffle the set of pairs $(i, j)$
--
    - For each $(i, j)$:
      - Sample item $k$ uniformly at random
--
      - Call item $k$ a negative item for user $i$
--
      - Train model on triplet $(i, j, k)$

???

This is called uniform negative sampling.

Note that new negative samples are collected for each pass
(epoch) over the positive feedback dataset.

It also possible to use the current state of the model to
"mine" hard negatives.

---
.center[
<img src="images/youtube-neural-recsys.png" style="width: 75%;" />

Deep Neural Networks for YouTube Recommendations
https://research.google.com/pubs/pub45530.html
]

???
Alternative way to deal with Implicit Feedback:

- no user embedding in input, the user is represented by averaged
  embeddings of movie watches (and queries)

- the output is a classification loss: 1 for the next movie being
  watched by the user.

- possible to model users by sequences of passed interactions with
  ordering information

---
class: middle, center

# Ethical Considerations of Recommender Systems

---
# Ethical Considerations

### Amplification of existing discriminatory and unfair behaviors / bias

- Example: gender bias in ad clicks (fashion / jobs)
- Using the firstname as a predictive feature

--

### Amplification of the filter bubble and opinion polarization

- People tend to unfollow people they don't agree with
- Ranking / filtering systems can further amplify this issue
- Optimizing for short-term clicks can promote clickbait contents

---
# Call to action

### Designing Ethical Recommender Systems

- Wise modeling choices (e.g. use of "firstname" as feature)
- Conduct internal audits to detect fairness issues
- Learning representations that actively enforce fairness?

--

### Transparency

- Educate decision makers and the general public
- How to allow users to assess fairness by themselves?
- How to allow for independent audits while respecting the privacy of users?

--

.center[
### Active Area of Research
]

???
# Fairness

Censoring Representations with an Adversary
Harrison Edwards, Amos Storkey, ICLR 2016
https://arxiv.org/abs/1511.05897

# Transparency

- http://www.datatransparencylab.org/
- TransAlgo initiative in France

---
class: middle, center

# Thank you for your attention!

Notebooks with keras code linked as pinned tweet:

@ogrisel


    </textarea>
    <style TYPE="text/css">
      code.has-jax {font: inherit; font-size: 100%; background: inherit; border: inherit;}
    </style>
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
      tex2jax: {
      inlineMath: [['$','$'], ['\\(','\\)']],
      skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'] // removed 'code' entry
      }
      });
      MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
      for(i = 0; i < all.length; i += 1) {
		     all[i].SourceElement().parentNode.className += ' has-jax';
		     }
		     });
		     </script>
    <script type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script src="../remark.min.js" type="text/javascript">
    </script>
    <script type="text/javascript">
      var slideshow = remark.create({
        highlightStyle: 'github',
        highlightSpans: true,
        highlightLines: true
      });
    </script>
  </body>
</html>
